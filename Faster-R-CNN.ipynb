{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11-pUe0pYnkc"
   },
   "source": [
    "# Faster R-CNNColab実装！\n",
    "コードにちょくちょく至らぬところはあると思いますがご容赦願います"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_vUhWu-ZQkb"
   },
   "source": [
    "## 前準備(Google Colab用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1095,
     "status": "ok",
     "timestamp": 1606669464440,
     "user": {
      "displayName": "Ryunosuke Ikeda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiS9DtIAhPRj07F4HTWzrudVufWf2zxpszujnRIGA=s64",
      "userId": "14496248625059375745"
     },
     "user_tz": -540
    },
    "id": "lA8XE1eOZXMY",
    "outputId": "c3c43923-6b9c-4183-85c7-90c515d80c0d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7CIcDcPsLvJ"
   },
   "source": [
    "## インポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1455,
     "status": "ok",
     "timestamp": 1606669464810,
     "user": {
      "displayName": "Ryunosuke Ikeda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiS9DtIAhPRj07F4HTWzrudVufWf2zxpszujnRIGA=s64",
      "userId": "14496248625059375745"
     },
     "user_tz": -540
    },
    "id": "RifmvJchbYN1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import xml.etree.ElementTree as ET \n",
    "import cv2\n",
    " \n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torch.utils.data import TensorDataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パスの指定(Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1455,
     "status": "ok",
     "timestamp": 1606669464810,
     "user": {
      "displayName": "Ryunosuke Ikeda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiS9DtIAhPRj07F4HTWzrudVufWf2zxpszujnRIGA=s64",
      "userId": "14496248625059375745"
     },
     "user_tz": -540
    },
    "id": "RifmvJchbYN1"
   },
   "outputs": [],
   "source": [
    "#pathの指定(colab_frcnn直下まで)\n",
    "path='/content/drive/My Drive/research/colab_frcnn-main/'\n",
    "bdd_xml=path+\"/kuzushiji/xml\"\n",
    "bdd_img=path+\"/kuzushiji/train_images\"\n",
    "test_path=path+\"/kuzushiji/d_test_images\"\n",
    "\n",
    "#datasetのクラス指定\n",
    "dataset_class_csv = pd.read_csv(path+ '/kuzushiji/unicode_translation.csv')\n",
    "dataset_class = dataset_class_csv.T.values.tolist()[0]\n",
    "#print(dataset_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パスの指定(SageMaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1455,
     "status": "ok",
     "timestamp": 1606669464810,
     "user": {
      "displayName": "Ryunosuke Ikeda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiS9DtIAhPRj07F4HTWzrudVufWf2zxpszujnRIGA=s64",
      "userId": "14496248625059375745"
     },
     "user_tz": -540
    },
    "id": "RifmvJchbYN1"
   },
   "outputs": [],
   "source": [
    "#pathの指定(colab_frcnn直下まで)\n",
    "path='s3://sagemaker-kuzushiji-01/'\n",
    "bdd_xml=path+\"xml\"\n",
    "bdd_img=path+\"train_images\"\n",
    "test_path=path+\"d_test_images\"\n",
    "\n",
    "#datasetのクラス指定\n",
    "dataset_class_csv = pd.read_csv(path+ 'unicode_translation.csv')\n",
    "dataset_class = dataset_class_csv.T.values.tolist()[0]\n",
    "#print(dataset_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1455,
     "status": "ok",
     "timestamp": 1606669464810,
     "user": {
      "displayName": "Ryunosuke Ikeda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiS9DtIAhPRj07F4HTWzrudVufWf2zxpszujnRIGA=s64",
      "userId": "14496248625059375745"
     },
     "user_tz": -540
    },
    "id": "RifmvJchbYN1"
   },
   "outputs": [],
   "source": [
    "#表示したいラベルの色の指定\n",
    "#注意！！一番最初は背景クラスを示すので(0,0,0)にする\n",
    "colors = ((0,0,0),(255,0,0),(0,255,0),(0,0,255),(100,100,100),(50,50,50),(255,255,0),(255,0,255),(0,255,255),(100,100,0),(0,100,100))\n",
    "\n",
    "#ハイパーパラメータの指定\n",
    "epochs=5\n",
    "batch_size=1\n",
    "scale=720#画像のスケール設定(縦の大きさを入力)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-X99T_8NY_QV"
   },
   "source": [
    "## その1データの読み込み（dataloaderの作成）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1452,
     "status": "ok",
     "timestamp": 1606669464811,
     "user": {
      "displayName": "Ryunosuke Ikeda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiS9DtIAhPRj07F4HTWzrudVufWf2zxpszujnRIGA=s64",
      "userId": "14496248625059375745"
     },
     "user_tz": -540
    },
    "id": "jGmayaWsZJPT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import xml.etree.ElementTree as ET \n",
    "import cv2\n",
    " \n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torch.utils.data import TensorDataset\n",
    "import os\n",
    "\n",
    "\n",
    "class xml2list(object):\n",
    "    \n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "        \n",
    "    def __call__(self, xml_path):\n",
    "        \n",
    "        ret = []\n",
    "        xml = ET.parse(xml_path).getroot()\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        zz=0\n",
    "        \n",
    "        for zz,obj in enumerate(xml.iter('object')):\n",
    "            \n",
    "            label = obj.find('name').text\n",
    "          \n",
    "            ##指定クラスのみ\n",
    "\n",
    "            if label in self.classes :\n",
    "                bndbox = obj.find('bndbox')\n",
    "                xmin = int(bndbox.find('xmin').text)\n",
    "                ymin = int(bndbox.find('ymin').text)\n",
    "                xmax = int(bndbox.find('xmax').text)\n",
    "                ymax = int(bndbox.find('ymax').text)\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "                labels.append(self.classes.index(label))\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "        num_objs = zz +1\n",
    "\n",
    "        anno = {'bboxes':boxes, 'labels':labels}\n",
    "\n",
    "        return anno,num_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1902,
     "status": "ok",
     "timestamp": 1606669465265,
     "user": {
      "displayName": "Ryunosuke Ikeda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiS9DtIAhPRj07F4HTWzrudVufWf2zxpszujnRIGA=s64",
      "userId": "14496248625059375745"
     },
     "user_tz": -540
    },
    "id": "dIPGNEQjZ0ax"
   },
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "        def __init__(self,image_dir,xml_paths,scale,classes):\n",
    "            \n",
    "            super().__init__()\n",
    "            self.image_dir = image_dir\n",
    "            self.xml_paths = xml_paths\n",
    "            self.image_ids = sorted(glob('{}/*'.format(xml_paths)))\n",
    "            self.scale=scale\n",
    "            self.classes=classes\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "    \n",
    "            transform = transforms.Compose([\n",
    "                                            transforms.ToTensor()\n",
    "            ])\n",
    "    \n",
    "            # 入力画像の読み込み\n",
    "            image_id=self.image_ids[index].split(\"/\")[-1].split(\".\")[0]\n",
    "            image = Image.open(f\"{self.image_dir}/{image_id}.jpg\")\n",
    "            \n",
    "            \n",
    "            #画像のスケール変換\n",
    "            t_scale_tate=self.scale ##目標のスケール(縦)\n",
    "            #縮小比を計算\n",
    "            ratio=t_scale_tate/image.size[1]\n",
    "            ##目標横スケールを計算\n",
    "            t_scale_yoko=image.size[0]*ratio\n",
    "            t_scale_yoko=int(t_scale_yoko)\n",
    "            \n",
    "            #print('縮小前:',image.size)\n",
    "            #print('縮小率:',ratio)\n",
    "            #リサイズ\n",
    "            image = image.resize((t_scale_yoko,t_scale_tate))\n",
    "            #print('縮小後:',image.size)\n",
    "  \n",
    "            image = transform(image)\n",
    "        \n",
    "            transform_anno = xml2list(self.classes)\n",
    "            path_xml=f'{self.xml_paths}/{image_id}.xml'\n",
    "            \n",
    "\n",
    "            annotations,obje_num= transform_anno(path_xml)\n",
    "\n",
    "            boxes = torch.as_tensor(annotations['bboxes'], dtype=torch.int64)\n",
    "            labels = torch.as_tensor(annotations['labels'], dtype=torch.int64)\n",
    "\n",
    "          \n",
    "            #bboxの縮小\n",
    "            #print('縮小前:',boxes)\n",
    "            boxes=boxes*ratio\n",
    "            #print('縮小後:',boxes)\n",
    "        \n",
    "            area = (boxes[:, 3]-boxes[:, 1]) * (boxes[:, 2]-boxes[:, 0])\n",
    "            area = torch.as_tensor(area, dtype=torch.float32)\n",
    "\n",
    "            iscrowd = torch.zeros((obje_num,), dtype=torch.int64)\n",
    "\n",
    "            target = {}\n",
    "            target[\"boxes\"] = boxes\n",
    "            target[\"labels\"] = labels+1\n",
    "            target[\"image_id\"] = torch.tensor([index])\n",
    "            target[\"area\"] = area\n",
    "            target[\"iscrowd\"] = iscrowd\n",
    "            return image, target,image_id\n",
    "        \n",
    "        def __len__(self):\n",
    "\n",
    "            return len(self.image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1899,
     "status": "ok",
     "timestamp": 1606669465266,
     "user": {
      "displayName": "Ryunosuke Ikeda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiS9DtIAhPRj07F4HTWzrudVufWf2zxpszujnRIGA=s64",
      "userId": "14496248625059375745"
     },
     "user_tz": -540
    },
    "id": "uX9PzZsmZ91m"
   },
   "outputs": [],
   "source": [
    "def dataloader (data,dataset_class,batch_size,scale=720):\n",
    "    xml_paths=data[0]\n",
    "    image_dir1=data[1]\n",
    "    dataset = MyDataset(image_dir1,xml_paths,scale,dataset_class)\n",
    "\n",
    "    #データのロード\n",
    "    torch.manual_seed(2020)\n",
    "    def collate_fn(batch):\n",
    "        return tuple(zip(*batch))\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_fn)\n",
    "    \n",
    "\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEsc2NU_dnO_"
   },
   "source": [
    "# modelの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1894,
     "status": "ok",
     "timestamp": 1606669465266,
     "user": {
      "displayName": "Ryunosuke Ikeda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiS9DtIAhPRj07F4HTWzrudVufWf2zxpszujnRIGA=s64",
      "userId": "14496248625059375745"
     },
     "user_tz": -540
    },
    "id": "szXr26nMdsPG"
   },
   "outputs": [],
   "source": [
    "def model ():\n",
    "    #モデルの定義\n",
    "    \n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    num_classes=len(dataset_class)+1\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Q6suCfofTrW"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 400643,
     "status": "ok",
     "timestamp": 1606669864018,
     "user": {
      "displayName": "Ryunosuke Ikeda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiS9DtIAhPRj07F4HTWzrudVufWf2zxpszujnRIGA=s64",
      "userId": "14496248625059375745"
     },
     "user_tz": -540
    },
    "id": "BjlidwrNgO_D",
    "outputId": "47a4f9c2-b0d5-4e75-ddb5-4a093f3f0512"
   },
   "outputs": [],
   "source": [
    "data_ALL=[bdd_xml,bdd_img]\n",
    "train_dataloader=dataloader(data_ALL,dataset_class,batch_size,scale)\n",
    "\n",
    "model=model()\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "num_epochs = epochs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "model.train()#学習モードに移行\n",
    "\n",
    "loss_list=[]\n",
    "for epoch in range(num_epochs):\n",
    "    loss_epo=[]\n",
    " \n",
    "    #model.train()#これから学習しますよ\n",
    "    \n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        \n",
    " \n",
    "        images, targets, image_ids = batch#####　batchはそのミニバッジのimage、tagets,image_idsが入ってる\n",
    "        \n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        \n",
    "        ##学習モードでは画像とターゲット（ground-truth）を入力する\n",
    "        ##返り値はdict[tensor]でlossが入ってる。（RPNとRCNN両方のloss）\n",
    "        loss_dict= model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #lossの保存\n",
    "        loss_epo.append(loss_value)\n",
    " \n",
    "        if (i+1) % 10== 0:\n",
    "          print(f\"epoch #{epoch+1} Iteration #{i+1} loss: {loss_value}\") \n",
    "          \n",
    "        \n",
    "    #Epochごとのlossの保存\n",
    "    loss_list.append(np.mean(loss_epo))\n",
    "    torch.save(model, path+'model' + str(epoch) + '.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4veUx8uZklKJ"
   },
   "source": [
    "# Test\n",
    "学習結果をもとに結果をテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 400937,
     "status": "ok",
     "timestamp": 1606669864318,
     "user": {
      "displayName": "Ryunosuke Ikeda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiS9DtIAhPRj07F4HTWzrudVufWf2zxpszujnRIGA=s64",
      "userId": "14496248625059375745"
     },
     "user_tz": -540
    },
    "id": "Q62oU8A4keWe"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "data_class=dataset_class\n",
    "data_class.insert(0, \"__background__\")\n",
    "classes = tuple(data_class)\n",
    "\n",
    "#学習済みモデルで推論する場合\n",
    "model=torch.load(path+'/model2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 403088,
     "status": "ok",
     "timestamp": 1606669866476,
     "user": {
      "displayName": "Ryunosuke Ikeda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiS9DtIAhPRj07F4HTWzrudVufWf2zxpszujnRIGA=s64",
      "userId": "14496248625059375745"
     },
     "user_tz": -540
    },
    "id": "WZEMyIZhkj8K",
    "outputId": "b30840e8-26f4-493d-8bf5-a38bce39741a"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "for imgfile in sorted(glob.glob(test_path+'/*')):\n",
    "    \n",
    "    img = cv2.imread(imgfile)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    image_tensor = torchvision.transforms.functional.to_tensor(img)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model([image_tensor.to(device)])\n",
    "    \n",
    "    for i,box in enumerate(prediction[0]['boxes']):\n",
    "        score = prediction[0]['scores'][i].cpu().numpy()\n",
    "        if score > 0.5:\n",
    "            score = round(float(score),2)\n",
    "            cat = prediction[0]['labels'][i].cpu().numpy()\n",
    "            txt = '{} {}'.format(classes[int(cat)], str(score))\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cat_size = cv2.getTextSize(txt, font, 2, 2)[0]\n",
    "            c = (255,0,0)\n",
    "            box=box.cpu().numpy().astype('int')\n",
    "            cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), c , 2)\n",
    "            cv2.rectangle(img,(box[0], box[1] - cat_size[1] - 2),(box[0] + cat_size[0], box[1] - 2), c, -1)\n",
    "            cv2.putText(img, txt, (box[0], box[1] - 2), font, 2, (0, 0, 0), thickness=1, lineType=cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNnHF3EgDHni8MRyuXcglrE",
   "collapsed_sections": [],
   "name": "Faster-R-CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/pytorch-1.6-cpu-py36-ubuntu16.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
